Background  
====
Autonomous navigation in unknown indoor environments using an RGB-D camera is a challenging task, especially when utilizing the feature-based visual simultaneous localization and mapping (SLAM) methods. The existence of low-texture scenes, such as narrow corridors and white walls, may lead to frequent tracking failure of indoor features. Recent works show that incorporating some form of map-like spatial memory can aid the performance of visual navigation. Therefore, we propose to add saliency information to map-like spatial memory to enable the learning-based agent to be better aware of the obstacle positions and visual importance of different regions, thus better avoiding tracking failure issues in low-texture environments. Visual saliency or visual attention mechanism refers to mimic the human vision system to select the most salient and interesting features from natural scenes for further processing under different tasks. This is also very important for visual navigation because visual saliency awareness directs the agentâ€™s perceptual attention towards the salient regions containing sufficient visual features in the process of approaching the target.
